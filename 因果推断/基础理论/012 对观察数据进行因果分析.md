#实验设计 #案例 #悖论
# 一、对观察数据进行因果分析
## **为什么观察数据难做因果分析？**

因为：

- 人不是随机分组
- 存在混杂变量（confounders）
- 存在内生性
- 可能有自我选择、自我筛选
- 反向因果（endogeneity）

比如：

> 看到锻炼的人更健康，但其实可能是因为健康的人更爱锻炼。

所以：

> **相关 ≠ 因果**

著名的有辛普森悖论和伯克森悖论。

---

## **因果推断的核心逻辑：反事实框架**

现代因果推断都建立在 **反事实（counterfactual）** 思想上。

- 每个人都有两个潜在结果：
    - Y(1)Y(1)：接受处理时的结果
    - Y(0)Y(0)：不接受处理时的结果

因果效应（treatment effect）：

$\text{TE}_i = Y_i(1) - Y_i(0)$

但问题是：

- 我只能看到其中一个结果（“现实”）
- 看不到另一个结果（“反事实”）

因此，所有因果分析方法都在试图：

> 用 **可观测的数据** 去推断 **不可观测的反事实**。

---

## **观察数据因果分析的方法**

### **1. 回归分析 + 控制变量**

最简单的思路：

$Y_i = \beta_0 + \beta_1 T_i + \gamma X_i + \varepsilon_i$

其中：

- $T_i$：处理变量
- $X_i$：控制变量

只要能控制所有混杂变量，$\beta_1$ 就是因果效应。

但问题：

- 如果遗漏了重要变量 → 内生性仍然存在。
### **2. 工具变量法（IV）**

如果：

- TT 内生（与误差相关）

则需要一个工具变量 ZZ：

- 与 TT 强相关
- 与 YY 无关，且不直接影响 YY

经典方法：

- 两阶段最小二乘（2SLS）

例：

- 用距离健身房远近，作为锻炼的工具变量 → 估计锻炼对健康的因果效应。

### **3. 双重差分法（DID）**

如果有政策冲击或外部事件：

- 比较处理组 vs. 对照组，在事件前后的变化

$\text{DID} = \big( Y_{T, post} - Y_{T, pre} \big) - \big( Y_{C, post} - Y_{C, pre} \big)$

要求：

- 趋势平行假设（parallel trends）

### **4. 匹配方法（Matching）**

通过匹配，使处理组和对照组在观测变量上“相似”。

常用：

- 倾向得分匹配（Propensity Score Matching, PSM）
- 最近邻匹配
- 半径匹配

核心思想：

- 用观测数据去“模拟”随机实验。

局限：

- 无法控制未观测混杂变量。

### **5. 回归断点设计（RD Design）**

如果处理是由某个分数阈值决定：

- 比如成绩 > 60 分才进实验班

则可以比较阈值两边的人：

- 越接近阈值，两组人越相似。

### **6. 控制函数法（Control Function）**

适用于非线性模型：

- 比如 Probit、Tobit

先建模内生变量，再把残差放进主回归。

### **7. 结构方程模型（SEM）**

用路径分析和结构方程同时处理：

- 多重因果链
- 潜变量

### **8. Causal Graphs / DAGs**

Pearl 的因果图：

- 用图形化方式表示变量之间的因果路径
- 判断哪些变量需要控制

比如：

- Backdoor Criterion → 解决混杂

### **9. G-Computation / g-formula**

用于处理时间依赖的因果关系：

- 尤其在流行病学非常常用

### **10. Machine Learning 与因果推断结合**

最近几年很火：

- Causal Forest
- Double Machine Learning
- Bayesian Additive Regression Trees (BART)

它们通过灵活拟合复杂关系，减少模型设定偏误。

## **分析流程**

做观察数据因果推断，大致流程：

✅ 明确研究问题  
→ 因果问题还是预测问题？

✅ 绘制因果图  
→ 明确潜在混杂、反向因果

✅ 判断数据类型  
→ 横截面、面板、断点？

✅ 选择方法  
→ IV、DID、RD、匹配？

✅ 检验稳健性  
→ 平行趋势检验、工具变量检验

✅ 报告结果  
→ 报告假设、限制条件、外部效度

---

## ⭐ 小例子

比如你研究：

> **锻炼对健康的因果影响**

- OLS 回归 → 加控制变量（年龄、收入、基线健康）
- 匹配 → 匹配生活方式相似的人
- DID → 若城市出台健身补贴政策
- IV → 用距离健身房远近做工具变量
- RD → 若健身补贴有收入门槛
- DAG → 绘制混杂路径

这就是观察数据因果推断的多种武器库。

---

## **局限**

- 无法完全消除未观测混杂
- 假设较强（如平行趋势、工具变量外生性）
- 结果解释常有限于特定群体（外部效度问题）

---

# ✨ 小结

| 方法          | 核心用途       |
| ----------- | ---------- |
| 回归 + 控制变量   | 控制观测混杂     |
| 工具变量（IV）    | 解决内生性、反向因果 |
| 双重差分（DID）   | 政策冲击、面板数据  |
| 匹配          | 减少观测混杂     |
| 回归断点（RD）    | 自然分组、阈值设计  |
| 因果图 / DAG   | 确定需要控制哪些变量 |
| 结构方程模型（SEM） | 同时建模多条因果链  |
| Causal ML   | 灵活拟合复杂因果效应 |

# # 二、辛普森悖论

## 什么是辛普森悖论？

辛普森悖论是指：**当我们把数据分组或者“分层”分析时，分组内的趋势与总体的趋势方向相反。**

换句话说：

- 在各个子群体（组内）里，变量A和B之间可能都呈现一种关系（例如正相关）。
- 但当把这些子群体合并到总体（不分组）一起分析时，变量A和B之间却表现出相反的关系（例如负相关）。

**这是统计分析里非常有意思、也很重要的现象。**

---
## 举个例子

最常见的一个经典例子是大学的录取率：

假设某大学两个系分别是：

- **系 X**：女生录取率 90%，男生录取率 85%
- **系 Y**：女生录取率 30%，男生录取率 25%

在两个系里，女生录取率都比男生高。

但如果：

- 大多数女生申请竞争激烈、录取率低的系 Y
- 大多数男生申请录取率高的系 X

整体来看，女生的录取总率可能低于男生。这就造成了：

- **各系内部** → 女生录取率高于男生
- **总体上** → 女生录取率低于男生

---
## 数学解释

辛普森悖论其实是加权平均的问题。总体数据是分组数据的加权平均，但权重不同可能“扭曲”总体趋势。

举个非常简化的例子：

假设两组数据：

- 组 A：女生成功率 90%（人数少）
- 组 B：女生成功率 30%（人数多）

如果大部分女生都集中在成功率低的组 B，则总体女生成功率会被拉低，可能低于男生的总体成功率。

---

## 为什么重要？

辛普森悖论在统计分析、医学研究、社会科学、甚至商业决策中都非常关键，因为：

- 容易误导结论
- 提醒我们考虑潜在的“混杂因素”
- 提醒我们要分层分析，而不是只看总体

---

## 应对辛普森悖论

- 分析数据时，要检查是否存在潜在的分层因素（confounders）。
- 分层报告数据，而不仅仅报告总体结果。
- 在统计建模里，考虑多变量分析（如回归分析）来控制混杂因素。

简言之，**辛普森悖论告诉我们：总体数据可能隐藏了更真实的分层信息。**

---
# 三、伯克森悖论

## 伯克森悖论的起源

1946年，美国生物统计学家伯克森（Joseph berkson）发现了一个奇怪的现象：两种疾病虽然在一般人群中不存在关系，但在住院病人中却会呈现出明显的相关性。

1979年，统计学家萨基特（David sacket）提供了强有力的证据。

> 传统观点认为，变量之所以会出现相关关系无外乎两种情形：以适当两个变量存在因果关系时；二是当两个变量不存在因果关系，但是有第三个变量共同影响这两个变量时。
> 在第二种情况下，变量间的相关性是虚假的，因此也被称作虚假相关（spurious correlation）。

珀尔和麦肯齐认为，之所以会出现伯克森悖论，是因为人们忽视了一种特殊的统计偏倚——[[对撞偏倚]]

伯克森悖论(**Berkson's Paradox**)指出在处理数据时，容易因为未能全面了解整个情况而误以为两个事物存在关联。这种错误可能对机器学习专家的预测模型准确性产生重大影响，因为它导致了对变量之间关系的错误假设。

通过一个例子来解释，例如，我们假设某学生的文化成绩较高，那么他的体育成绩就较差；反之，体育成绩越好，文化成绩就越差。这似乎已经成为我们日常观察中的一种认知，即班上的尖子生好像体育成绩普遍不太出色。那么，这种现象是如何出现的呢？

设想学生需要参加两种类型的考试，即文化和体育课，其中只要在任何一种类型的考试中获得90分以上就能顺利毕业。因此，毕业的学生要么在文化考试中取得90分以上，或者在体育考试中获得90分以上，或者在两门考试中都取得90分以上。通常情况下，正常人只需专注于其中一门考试，充分发挥至极致即可，而对另一门考试不太重视。因此，学生的文化成绩和体育成绩会呈现负相关的关系。

伯克森悖论还能解释为什么很多人都认为帅哥通常是渣男，以及为什么颜值超高的小鲜肉演员演技不尽人意，这些现象。

## **举个数值事例说明伯克森悖论**

见：[# 一文带您了解伯克森悖论：了解数据分析/机器学习中隐藏的偏差](https://zhuanlan.zhihu.com/p/680437821)

为了说明伯克森悖论(**Berkson's Paradox**)，接下来使用两个骰子：

- 事件 X：第一个骰子出现 6 点。
- 事件 Y：第二个骰子出现 1 点或 2 点。

这两个事件显然是独立的，其中 P(X)=1/6 而 P(Y)=1/3。

现在，让我们引入条件（Z），表示通过 第一个骰子是 6 点且第二个骰子是 1 点或 2 点的所有结果而引入的抽样偏差。

在我们的[[有偏抽样与幸存者谬误]]条件下，我们需要计算事件 X 发生的概率，假设至少其中一个事件（X 或 Y）发生，这由 P(X|Z) 表示。

首先，我们需要确定 Z = (X ∪ Y) 的概率(即在已知第一个骰子是 6 点或第二个骰子是 1 点或 2 点的情况下，第一个骰子出现 6 点的概率)：


_P(Z)=P(X∪Y)_

_=P(X)+P(Y)−P(X∩Y)_

_=P(X)+P(Y)-P(X)×P(Y)_

_=1/6+1/3-1/6×1/3_

_=4/9_

接下来，我们计算给定 Z 的 X 的概率：

_P_(_X∣Z_)_=P(X∩Z)/P(Z)=P(X)/P(Z)_

_=1/6 / (4/9)_

_=3/8_

_=0.375_

为了查看在 Z 发生的假设下 X 和 Y 之间是否存在依赖关系，我们必须计算(已知第二个骰子是 1 点或 2 点的情况下，同时第一个骰子是 6 点的情况下，第一个骰子出现 6 点的概率):

P(X | Y ∩ Z) ≈ 0.1666…

上述数据确实得到了伯克森悖论的特性，由于抽样偏差 Z，我们有 P(X | Z) > P(X ∣ Y ∩ Z)。

是不是这相当令人惊讶！我们有两个骰子…两个明显独立的随机事件…通过一个抽样过程，我们会产生骰子点数变得相互依赖的印象。

## **Python模拟掷骰子的过程复现伯克森悖论**

在下面的代码中使用Python模拟掷骰子的过程。

以下代码模拟了一百万次掷两个骰子的实验，在每次实验中，它检查第一个骰子是否掷出6点（事件X），以及第二个骰子是否掷出1点或2点（事件Y）。然后，它将这些检查的结果（True或False）分别存储在列表X和Y中。

```python
import random

def sample_X_Y(nb_exp):
    X = []
    Y = []
    for i in range(nb_exp):
        dice1 = random.randint(1,6)
        dice2 = random.randint(1,6)
        X.append(dice1 == 6)
        Y.append(dice2 in [1,2])
    return X, Y

nb_exp=1_000_000
X, Y = sample_X_Y(nb_exp)
```

以下代码计算了事件X的概率和在事件Y发生的条件下事件X的[条件概率](https://zhida.zhihu.com/search?content_id=239338311&content_type=Article&match_order=1&q=%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87&zhida_source=entity)。它通过将成功的结果数量除以每个概率的总实验次数来完成这个计算。

```python
p_X = sum(X)/nb_exp
p_X_Y = sum([X[i] for i in range(nb_exp) if Y[i]])/sum(Y)

print("P(X=1) = ", round(p_X,5))
print("P(X=1|Y=1) = ", round(p_X_Y,5))
```

  

![](https://picx.zhimg.com/v2-264c86eea574646e22fac1cd4f57788b_1440w.jpg)

正如所看到的，这两个概率是接近的；因此两个骰子是独立的。

现在，让我们看看在引入抽样偏差Z时会发生什么。下面的代码过滤了实验的结果，仅保留那些其中X = 1，Y = 1或两者都为1的结果。它将这些过滤后的结果存储在列表XZ和YZ中。

```python
XZ = []
YZ = []
for i in range(nb_exp):
    if X[i] or Y[i]:
        XZ.append(X[i])
        YZ.append(Y[i]) 
nb_obs_Z = len(XZ)
```

现在，检查一下这些新变量是否仍然是独立的。

```python
p_X_Z = sum(XZ)/nb_obs_Z
p_X_Y_Z = sum([XZ[i] for i in range(nb_obs_Z) if YZ[i]])/sum(YZ)

print("P(X=1|Z=1) = ", round(p_X_Z,5))
print("P(X=1|Y=1,Z=1) = ", round(p_X_Y_Z,5))
```


![](https://pic3.zhimg.com/v2-ab2a71c741ebb188af3a3210e9014bfa_1440w.jpg)

这意味着如果Z为真，则拥有关于Y的信息会改变X的概率；因此，它们不再是独立的。

## **伯克森悖论悖论对机器学习的影响**

现实中，数据科学家或算法工程师们并没有足够关注这种类型的偏差。伯克森悖论悖论涉及到了我们如何被我们使用的数据误导的问题。伯克森悖论警告我们关于使用有偏或片面数据的危险。

- 信用评分系统：在金融领域，模型基于具有高收入或高信用评分的申请人的数据进行训练，但很少两者都有的情况，可能会错误地推断这些因素之间存在负相关。这可能导致不公平的借贷实践，偏向某些人口群体。
- 社交媒体算法：在社交媒体算法中，当在极端用户数据上训练模型时，比如在流行度很高但参与度很低的病毒性内容和在参与度深但流行度低的小众内容上，伯克森悖论可能会出现。这种有偏抽样通常导致错误的结论，即流行度和参与深度呈负相关。因此，算法可能低估那些平衡了适度流行和参与度的内容，从而偏离内容推荐系统。
- 求职申请者筛选工具：基于具有高学历或丰富经验的申请者的筛选模型可能会错误地暗示这些属性之间存在反向关系，从而可能忽视了平衡的候选人。

在每种情景中，忽视伯克森悖论可能导致有偏的模型，影响决策和公平性。机器学习专家必须通过多样化数据源并不断验证模型与实际场景相匹配，以抵消这种影响。

总而言之，伯克森悖论是机器学习专业人士提醒他们审查数据来源并避免误导性相关性的重要提醒。通过理解和考虑这一悖论，可以构建更准确、公平和实用的模型，真正反映现实世界的复杂性。记住，健壮的机器学习关键在于精密的算法和对数据的深思熟虑、全面的收集与分析。

# 四、挑战与应对

实际上，学术界一直对从观察数据推断因果持有严重甚至否定的态度。

例如，回归分析的提出者、英国著名遗传学家和统计学家高尔顿就对此深感疑虑。

## 因果革命

一是美国著名统计学家唐纳德·鲁宾（Donald Rubin）。他在一系列研究中提出了基于反事实的潜在结果框架（potential outcomes framework），用于明确地定义和推断因果效应。这一框架后来被称为鲁宾因果模型（Rubin Causal Model, RCM）。鲁宾因果模型强调通过比较同一个体在不同处理条件下的潜在结果来定义因果效应，奠定了现代统计因果推断的理论基础，尤其对随机试验设计、倾向评分方法（propensity score）以及缺失数据分析产生了深远影响。

二是美国著名计算机科学家裘德·珀尔（Judea Pearl）。珀尔的主要贡献是提出了结构因果模型（Structural Causal Model, SCM），并系统地发展了基于图论的因果推断方法。结构因果模型的核心工具是因果有向无环图（causal directed acyclic graph, DAG），学术界简称为因果图。通过因果图，珀尔提出了“do演算（do-calculus）”等方法，能够在复杂系统中识别因果关系、调整混杂因素，并进行干预效果的推断。珀尔的工作为因果推断提供了图形化、形式化的工具，在计算机科学、统计学、流行病学、社会科学等领域具有重大影响。

## Pearl 的因果推断策略

裘德·珀尔（Judea Pearl）提出的因果推断策略，核心是利用 **结构因果模型（SCM）** 和 **因果图（causal DAG）**，以及他独创的 **do-calculus（do演算）**，系统地解决以下问题：

1. **识别问题（Identification）**
    - 我能否仅依赖观察数据，推断出某个因果效应？
    - 条件：需要确定哪些变量是混杂因素（confounders），以及如何调整。
    - 工具：
        - **Back-door criterion（后门准则）**：识别需要控制哪些变量来阻断混杂路径。
        - **Front-door criterion（前门准则）**：在存在未观测混杂时，通过中介变量进行推断。
2. **干预推断（Intervention Inference）**
    - 不仅仅是观察相关性，而是回答“如果我做了某个干预，会发生什么？”
    - 用 **do-operator** 表示外部干预，例如：
         $P(Y \mid do(X = x))$
        表示当我们把 XX 人为设定为 xx 时，YY 的分布。
3. **反事实推断（Counterfactual Inference）**
    - 不仅想知道“如果我做了什么，会发生什么？”，还想回答：
        > “如果我没做这件事，结果会怎样？”
    - 例如：
         $P(Y_{x'} = y' \mid X = x, Y = y)$
        表示“对于已经接受 $X = x$ 且结果是 $Y = y$  的人，如果当初接受 $X=x′$，结果会不会是 $y'$ ？”
4. **模型检验与可解释性（Model Testing and Explanation）**
    - 因果图不只是做推断，也是沟通和假设检验的工具。
    - 珀尔强调因果图的直观解释力和可视化优势。

---

## Pearl 因果推断的三层次因果推理阶梯（Ladder of Causation）

这是 Pearl 在近年的著作中总结的经典思想：

|层次|类型|问题例子|工具|
|---|---|---|---|
|**关联 (Association)**|观察|“看见 X，Y 会怎样？”|统计相关、回归|
|**干预 (Intervention)**|操作|“如果我做 X，Y 会怎样？”|do-calculus、随机试验|
|**反事实 (Counterfactuals)**|想象|“如果我没做 X，结果会怎样？”|SCM、反事实模型|

多数传统统计方法停留在 **关联** 层次，而 Pearl 的贡献是系统地让我们进入 **干预** 和 **反事实** 的领域。

---

## Pearl 的核心工具

- **Causal DAG (因果有向无环图)**
    - 变量是节点
    - 有向边表示直接因果关系
- **do-operator**
    - 区分观察 $P(Y|X)$ 和干预 $P(Y∣do(X))$
- **do-calculus**
    - 三条推理规则
    - 用于在 DAG 上推导 P(Y∣do(X))P(Y|do(X)) 能否化为可观测概率表达式
- **Identification Criteria**
    - Back-door criterion
    - Front-door criterion

---

简而言之，**Pearl 的因果推断策略是：**

> **用因果图表达假设，用 do-calculus 化简因果效应，用反事实回答个体层面的问题。**

他把因果推断变成了一个系统、可操作、可检验的框架，这在统计学、人工智能、流行病学、社会科学等领域都产生了深远影响。